cda questions

Familiarization and discretization task –1 A4
Consider scenario 10 from the CTU-13 data sets (see paper 4 from below resources). Remove all background flows from the data. 

	Assignment:
	1. You are to discretize the NetFlows (Apply the discretization to data from all hosts in the selected scenario). 
	2. Investigate the data from one of the infected hosts. 
	3. Select and visualize two features that you believe are most relevant for modeling the behavior of the infected host. (criteria: Shows the behavior of two features conditioned on the infection status.)
	4. Discretize these features using use any of the methods discussed in class (combine the two values into a single discrete value). (criteria: The discretization is sound, and the result investigated)
	5. Do you observe any behavior in the two features that could be useful for detecting the infection? Explain and visualize. 


Frequent task – 1/2 A4 (Individual)
Use the SPACE SAVING algorithm to estimate the distribution over 3-grams of discretised symbols. 

	1. Write code for the algorithm, use it to estimate the distribution in one pass (no need to actually stream the data, you may store it in memory, or run every file separately, but do store and load the intermediate results). 
	2. Use a range of number of counters. (criteria: explanations for the number of used counters/bin)
	3. What are the 10 most frequent 3-grams and their frequencies when approximated? 
	4. Use the theory to explain any approximation errors you observe. (criteria: The 3-gram count approximation is correct, and its quality is related to theory)

Sketching task –1/2 A4 (Individual)
Build code for computing a COUNT-MIN sketch to estimate occurrence counts for the 3-grams. Make sure the hash functions are pairwise independent. 

	1. Estimate the distribution in one pass (no need to actually stream the data, you may store it in memory, or run every file separately, but do store and load the intermediate results). 
	2.	Play with different heights and widths for the COUNT-MIN sketch matrix. (criteria: explanations for the number of used counters/bin) 
	3.	What are the 10 most frequent 3-gramsand their frequencies when approximated? 
	4.	Use the theory to explain any approximation errors you observe. (criteria: The 3-gram count approximation is correct, and its quality is related to theory)

Min-wise locality sensitive hashingtask –1/2 A4 (Individual)
Implement min-wise locality sensitive hashing as explained in the slides and the documents on Brightspace. This can be used to quickly compute the Jaccard distance for N-gram profiles. 

	1.	Use the discretization from task 1, build 3-gram profiles for every individual connection (pair of IP-addresses). 
	2.	For this task, the profiles are binary, an N-gram (subsequence) exists (a 1 in the table) or does not (a 0 in the table). 
	3.	Use min-wise LSH to map the 3-gram profiles to a small set of bins of your choice. (Criteria: The number of bins is set sensibly)
	4.	Compare the run-time of a pair-wise distance computation with one that only considers profiles that end in the same bin. 
	5.	Explain any differences you observe. (criteria: The resulting comparison explains differences in run-time and quality.)

Random hyperplane locality sensitive hashingtask –1/2 A4 (Individual)
Implement locality sensitive hashing using random hyperplanes as explained in the slides and the documents on Brightspace. This can be used to quickly compute Euclidean distance for N-gram profiles.

	1.	Use the discretization from task 1, build 3-gram profilesfor every individual connection (pair of IP-addresses). 
	2.	For this task, the profiles are countsfor every possible 3-gram (subsequence).
	3.	Use random hyperplanes LSH to map the N-gram profiles to a small set of bins of your choice. 
	4.	Compare the run-time of a pair-wise distance computation with one that only considers profiles that end in the same bin. (criteria: The number of bins is set sensibly)
	5.	Explain any differences you observe. (criteria: The resulting comparison explains differences in run-time and quality.)

Botnet profiling task –1/2 A4

	1.	Use a sliding window to obtain sequence data for every host in all scenarios considered in paper 4 (with multiple infected hosts), with a length of your choice. (criteria: Advanced sequential model learning is used correctly, one for each host.)
	2.	Learn an n-gram model from the data of one infected host and match its profile (e.g., n-grams using cosine distance, or probabilities using KL-divergence) with all other hosts from the same scenario. 
	3.	Evaluate how many new infections your method finds and false positives it raises (as in paper 4) (criteria: Profile matching and evaluation are correct)

Botnet fingerprinting task –1/2 A4 

	1.	Use the obtained botnet profiles for fingerprinting, i.e., look for the occurrence of an n-gram that does not occur in any benign traffic. 
	2.	Whenever this subsequence occurs, you raise an alarm. 
	3.	Evaluate how many new infections your method finds and false positives it raises (as in paper 4).
	4.	Compare it to profiling and explain the results. (criteria:Fingerprinting is correctly applied. Comparison to profiling is sound and considers both run-time and the kinds of behaviors that can be detected)